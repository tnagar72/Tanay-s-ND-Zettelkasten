# Relevant Research Papers


| Paper Title                                                                                                                   | Authors                                                                                                                                                                                                                                                                                                                                                                                       | Journal/Conference | Publication Date | DOI/Link                                        | Notes                                                                                                     |
| ----------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------ | ---------------- | ----------------------------------------------- | --------------------------------------------------------------------------------------------------------- |
| From Machine Translation to Code-Switching: Generating High-Quality Code-Switched Text                                        | [Ishan Tarunesh](https://arxiv.org/search/cs?searchtype=author&query=Tarunesh,+I), [Syamantak Kumar](https://arxiv.org/search/cs?searchtype=author&query=Kumar,+S), [Preethi Jyothi](https://arxiv.org/search/cs?searchtype=author&query=Jyothi,+P)                                                                                                                                           | ACL                | 14th July, 2021  | https://arxiv.org/abs/2107.06483                | Re-Purposed encoder-decoder style MT architecture with specific pre-training steps for generating CS text |
| [CoCoa: An Encoder-Decoder Model for Controllable Code-switched Generation](https://aclanthology.org/2022.emnlp-main.158.pdf) | [Sneha Mondal](https://aclanthology.org/people/s/sneha-mondal/), [Ritika .](https://aclanthology.org/people/r/ritika/), [Shreya Pathak](https://aclanthology.org/people/s/shreya-pathak/), [Preethi Jyothi](https://aclanthology.org/people/p/preethi-jyothi/), [Aravindan Raghuveer](https://aclanthology.org/people/a/aravindan-raghuveer/)                                                 | EMNLP 2022         | December, 2022   | https://doi.org/10.18653/v1/2022.emnlp-main.158 | Bootstrapped the TCS model and added encoder and decoder side-control for better CS data output           |
| Don't Trust ChatGPT when Your Question is not in English: A Study of Multilingual Abilities and Types of LLMs                 | [Xiang Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+X), [Senyu Li](https://arxiv.org/search/cs?searchtype=author&query=Li,+S), [Bradley Hauer](https://arxiv.org/search/cs?searchtype=author&query=Hauer,+B), [Ning Shi](https://arxiv.org/search/cs?searchtype=author&query=Shi,+N), [Grzegorz Kondrak](https://arxiv.org/search/cs?searchtype=author&query=Kondrak,+G) | EMNLP 2023         | May, 2023        | https://doi.org/10.48550/arXiv.2305.16339       | Uses different tasks to show prompting has an effect on overall accuracy                                  |
